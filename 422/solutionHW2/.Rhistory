inspect(sort(rules, decreasing = F, by="confidence")[1:5])
cat("\n\n## Top support ---- \n")
inspect(sort(rules, decreasing = T, by="support")[1:5])
cat("\n\n## Top confidence ----- \n")
inspect(sort(rules, decreasing = T, by="confidence")[1:5])
inspect(sort(rules, decreasing = F, by="support")[1:5])
inspect(sort(rules, decreasing = F, by="confidence")[1:5])
cat("\n\n## Top support ---- \n")
inspect(sort(rules, decreasing = T, by="support")[1:5])
cat("\n\n## Top confidence ----- \n")
inspect(sort(rules, decreasing = T, by="confidence")[1:5])
cat("\n\n## Minimum Support ----- \n")
inspect(sort(rules, decreasing = F, by="support")[1:5])
cat("\n\n## Minimum confidence ----- \n")
inspect(sort(rules, decreasing = F, by="confidence")[1:5])
itemFrequencyPlot(trans, support = 0.1)
itemFrequencyPlot(trans, support = 0.2)
itemFrequencyPlot(trans, support = 0.1)
itemFrequencyPlot(trans, support = 0.15)
itemFrequencyPlot(trans, support = 0.14)
itemFrequencyPlot(trans, support = 0.12)
names(trans)
names(summary(trans))
trans
summary(trans)
itemFrequencyPlot(trans, support = 0.12)
sprintf("\n\n ### Most Frequently bought ---- \n ")
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Item frequency, absolute')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
horiz=TRUE,
las=1,
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
las=1,
col='orange',
xlab='',
main='Least frequently bought items')
sort(table(unlist(LIST(trans))))[1:5]
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
sort(table(unlist(LIST(trans))))[1:5]
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
sort(table(unlist(LIST(trans))))[1:5][,1]
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
sort(table(unlist(LIST(trans))))[1:5]
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
plot(sort(table(unlist(LIST(trans))))[1:5],
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
col='orange',
xlab='',
main='Least frequently bought items')
legend("topright")
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
horiz=TRUE,
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
beside=TRUE,
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
beside=F,
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
beside=FALSE,
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:5],
beside=FALSE,
col='orange',
xlab='',
main='Least frequently bought items')
itemFrequencyPlot(trans,
type="absolute",
topN=5,
col='gold',
xlab='',
main='Most Frequently bought Item')
sort(table(unlist(LIST(trans))))[1:5]
itemFrequencyPlot(trans,
type="absolute",
topN=1,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:1],
=FALSE,
itemFrequencyPlot(trans,
type="absolute",
topN=1,
col='gold',
xlab='',
main='Most Frequently bought Item')
barplot(sort(table(unlist(LIST(trans))))[1:1],
horiz=TRUE,
col='orange',
xlab='',
main='Least frequently bought items');
sort(table(unlist(LIST(Groceries))))[1:1]
sort(table(unlist(LIST(trans))))[1:1]
sprintf("least frequently bought %s",sort(table(unlist(LIST(trans))))[1:1])
sprintf("least frequently bought ",sort(table(unlist(LIST(trans))))[1:1])
sprintf("least frequently bought ")
sort(table(unlist(LIST(trans))))[1:1])
sprintf("least frequently bought ")
sort(table(unlist(LIST(trans))))[1:1]))
sprintf("least frequently bought ")
sort(table(unlist(LIST(trans))))[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))))[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))), TRUE)[1:1]
sprintf("Most frequently bought item and frequency")
sort(table(unlist(LIST(trans))), TRUE)[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))))[1:1]
sprintf("Most frequently bought item and frequency")
sort(table(unlist(LIST(trans))), TRUE)[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))))[1:2]
sprintf("Most frequently bought item and frequency")
sort(table(unlist(LIST(trans))), TRUE)[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))))[1:3]
sprintf("Most frequently bought item and frequency")
sort(table(unlist(LIST(trans))), TRUE)[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))))[1:2]
adult.model <- rpart(income ~ ., method="class", data=adult.train)
#Load libraries
library(rpart)
library(caret)
library(rpart.plot)
library(ROCR)
options("digits"=3)
rm(list=ls())
# Load the Diabetes dataset and set seed
setwd("~/Desktop/Assignments&Coursework/422/Hw-2-March4/")
set.seed(1122)
adult.train <- read.csv("adult-train.csv", header=T, sep=",")
adult.test <- read.csv("adult-test.csv", header=T, sep=",")
dim(adult.train)
dim(adult.test)
delete.dirt <- function(DF, dart=c('?')) {
dirty_rows <- apply(DF, 1, function(r) !any(r %in% dart))
DF <- DF[dirty_rows, ]
}
adult.train <- delete.dirt(adult.train)
adult.test <- delete.dirt(adult.test)
dim(adult.train)
dim(adult.test)
adult.model <- rpart(income ~ ., method="class", data=adult.train)
rpart.plot(adult.model, extra=104, type=4, main="Adult Income")
adult.model$variable.importance[1:3]
sprintf("The first split is done on predictor -> %s", rownames(adult.model$splits)[1])
sprintf("Predicted class of 1st Node -> %s", "<=50K")
sprintf("distribution of the <=50K and >50K at RootNode -> %s", ".6")
adult.pred <- predict(adult.model, adult.test, type="class")
cMat <- confusionMatrix(adult.pred, adult.test[,15])
cMat
print.AESeSp <- function(DF) {
cat(sprintf("Balanced accuracy of the model -> %.3f\n", DF$byClass[11]))
cat(sprintf("Balanced Error of the model -> %.3f\n", 1 - DF$byClass[11]))
cat(sprintf("Specificity of the model -> %.3f\n", DF$byClass[2]))
cat(sprintf("Sensitivity of the model -> %.3f\n", DF$byClass[1]))
}
print.AESeSp(cMat);
pred.rocr <- predict(adult.model, newdata=adult.test, type="prob")[,2]
f.pred <- prediction(pred.rocr, adult.test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
printcp(adult.model)
adult.model$cptable[which.min(adult.model$cptable[,"xerror"]), ]
sprintf("Number of observations are in the class <=50K are %d", sum(adult.train$income == "<=50K"))
sprintf("Number of observations are in the class >50K are %d", sum(adult.train$income == ">50K"))
GR50K_ind <- which(adult.train$income == ">50K")
LE50K_ind <- which(adult.train$income == "<=50K")
nsamp <- length(GR50K_ind)
pick_GR50K_ind <- sample(GR50K_ind, nsamp)
pick_LE50K_ind <- sample(LE50K_ind, nsamp)
newTrainingDataset <- adult.train[c(pick_GR50K_ind, pick_LE50K_ind), ]
sprintf("Number of observations are in the class <=50K are %d", sum(newTrainingDataset$income == "<=50K"))
sprintf("Number of observations are in the class >50K are %d", sum(newTrainingDataset$income == ">50K"))
balanced.model <- rpart(income ~ ., method="class", data=newTrainingDataset)
balanced.pred <- predict(balanced.model, adult.test, type="class")
balancedCM <- confusionMatrix(balanced.pred, adult.test[,15])
print.AESeSp(balancedCM)
pred.rocr <- predict(balanced.model, newdata=adult.test, type="prob")[,2]
f.pred <- prediction(pred.rocr, adult.test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
library(randomForest)
forest.model <- randomForest(income ~ ., data = adult.train, importance=T)
forest.pred <- predict(forest.model, adult.test, type="class")
forestCM <- confusionMatrix(forest.pred, adult.test$income)
print(forestCM)
print.AESeSp(forestCM)
options("digits"=3)
sprintf("Accuracy of the model %f",forestCM$overall["Accuracy"])
sprintf("Total observations labelled as <=50K are %s",sum(forestCM$table[1,]))
sprintf("Total observations labelled as >50K are %s",sum(forestCM$table[2,]))
sprintf("Ans to (v) Given the response class distribution this makes sense. As there is a data imbalance , Random forest does increase sensitivity of the model at the cost of Specificity")
varImp <- varImpPlot(forest.model)
sprintf("Ans to (vi) MeanDecreaseAccuracy - Most Important 'capital_gain', least Important 'native_country' . MeanDecreaseGini - most important 'capital_gain', least important 'race'" )
print(forest.model)
sprintf("(vii) What is the number of variables tried at each split -> %s", 3 )
mtry <- tuneRF(adult.train[, names(adult.train) != "income"], adult.train[, names(adult.train) == "income"], ntreeTry=500,stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
print(mtry)
sprintf("Ans to (i) What is the default value of mtry - %s", floor(log(15, 2)))
sprintf("(ii) what is the optimal value of mtry? - Optimal when mtry = 2, { ...2.OOB    2    0.178}")
forest.mtry.model <- randomForest(income ~ ., data = adult.train, importance=T, mtry=2)
forest.mtry.pred <- predict(forest.mtry.model, adult.test, type="class")
forestMtryCM <- confusionMatrix(forest.mtry.pred, adult.test$income)
print(forestMtryCM)
varImp <- varImpPlot(forest.mtry.model)
sprintf("Ans to (5) MeanDecreaseAccuracy - Most Important 'capital_gain', least Important 'native_country' . MeanDecreaseGini - most important 'capital_gain', least important 'race'" )
print("There is a significant improvement in Balanced accuracy and Specificity, as now we are using optimal mTree split this was expected")
setwd("~/Desktop/Assignments&Coursework/422/Hw-2-March4/")
trans <- read.transactions("groceries.csv", sep=",")
summary(trans)
rules <- apriori(trans)
rm(rules)
sprintf("Ans - (i) Got 0 rules for default support value of 0.1")
rules <- apriori(trans, parameter = list(support=0.001))
summary(rules)
sprintf("Ans - (ii)Got 410 rules for default support value of 0.001")
sprintf("Most frequently bought item and frequency")
sort(table(unlist(LIST(trans))), TRUE)[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))))[1:2]
cat("\n\n## Top support ---- \n")
inspect(sort(rules, decreasing = T, by="support")[1:5])
cat("\n\n## Top confidence ----- \n")
inspect(sort(rules, decreasing = T, by="confidence")[1:5])
cat("\n\n## Minimum Support ----- \n")
inspect(sort(rules, decreasing = F, by="support")[1:5])
cat("\n\n## Minimum confidence ----- \n")
inspect(sort(rules, decreasing = F, by="confidence")[1:5])
forest.mtry.model <- randomForest(income ~ ., data = adult.train, importance=T, mtry=2)
forest.mtry.pred <- predict(forest.mtry.model, adult.test, type="class")
forestMtryCM <- confusionMatrix(forest.mtry.pred, adult.test$income)
print.AESeSp(forestMtryCM)
interestMeasure(trans, measure='lift', Groceries)
interestMeasure(rules, measure='lift', trans)
inspect(sort(rules, by ='lift', decreasing = T)[1:5])
quality(rules)$lift <- interestMeasure(rules, measure='lift', trans)
inspect(sort(rules, by ='lift', decreasing = T)[1:5])
setwd("~/Desktop/Assignments&Coursework/422/Hw-2-March4/")
x <- read.transactions("zaki.csv", sep=",")
x <- read.transactions("zaki.csv", sep=",")
x <- read.transactions("zaki.csv", sep=",")
rules <- apriori(trans, parameter = list(support=.375))
rules <- apriori(x, parameter = list(support=.375))
rules
inspect(rules
inspect(rules)
inspect(head(rules))
x
summary(x)
itemFrequency(x, type = "absolute")
trans <- x
f_is <- apriori(trans, parameter=list(support=0.25, target="frequent itemsets"))
inspect(sort(f_is, decreasing = T, by="count"))
View(newTrainingDataset)
#Load libraries
library(rpart)
library(caret)
library(rpart.plot)
library(ROCR)
options("digits"=3)
rm(list=ls())
# Load the Diabetes dataset and set seed
setwd("~/Desktop/Assignments&Coursework/422/Hw-2-March4/")
set.seed(1122)
adult.train <- read.csv("adult-train.csv", header=T, sep=",")
adult.test <- read.csv("adult-test.csv", header=T, sep=",")
dim(adult.train)
dim(adult.test)
delete.dirt <- function(DF, dart=c('?')) {
dirty_rows <- apply(DF, 1, function(r) !any(r %in% dart))
DF <- DF[dirty_rows, ]
}
adult.train <- delete.dirt(adult.train)
adult.test <- delete.dirt(adult.test)
dim(adult.train)
dim(adult.test)
adult.model <- rpart(income ~ ., method="class", data=adult.train)
rpart.plot(adult.model, extra=104, type=4, main="Adult Income")
adult.model$variable.importance[1:3]
sprintf("The first split is done on predictor -> %s", rownames(adult.model$splits)[1])
sprintf("Predicted class of 1st Node -> %s", "<=50K")
sprintf("distribution of the <=50K and >50K at RootNode -> %s", ".6")
adult.pred <- predict(adult.model, adult.test, type="class")
cMat <- confusionMatrix(adult.pred, adult.test[,15])
cMat
print.AESeSp <- function(DF) {
cat(sprintf("Balanced accuracy of the model -> %.3f\n", DF$byClass[11]))
cat(sprintf("Balanced Error of the model -> %.3f\n", 1 - DF$byClass[11]))
cat(sprintf("Specificity of the model -> %.3f\n", DF$byClass[2]))
cat(sprintf("Sensitivity of the model -> %.3f\n", DF$byClass[1]))
}
print.AESeSp(cMat);
pred.rocr <- predict(adult.model, newdata=adult.test, type="prob")[,2]
f.pred <- prediction(pred.rocr, adult.test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
printcp(adult.model)
adult.model$cptable[which.min(adult.model$cptable[,"xerror"]), ]
sprintf("Number of observations are in the class <=50K are %d", sum(adult.train$income == "<=50K"))
sprintf("Number of observations are in the class >50K are %d", sum(adult.train$income == ">50K"))
GR50K_ind <- which(adult.train$income == ">50K")
LE50K_ind <- which(adult.train$income == "<=50K")
nsamp <- length(GR50K_ind)
pick_GR50K_ind <- sample(GR50K_ind, nsamp)
pick_LE50K_ind <- sample(LE50K_ind, nsamp)
newTrainingDataset <- adult.train[c(pick_GR50K_ind, pick_LE50K_ind), ]
sprintf("Number of observations are in the class <=50K are %d", sum(newTrainingDataset$income == "<=50K"))
sprintf("Number of observations are in the class >50K are %d", sum(newTrainingDataset$income == ">50K"))
balanced.model <- rpart(income ~ ., method="class", data=newTrainingDataset)
balanced.pred <- predict(balanced.model, adult.test, type="class")
balancedCM <- confusionMatrix(balanced.pred, adult.test[,15])
print.AESeSp(balancedCM)
pred.rocr <- predict(balanced.model, newdata=adult.test, type="prob")[,2]
f.pred <- prediction(pred.rocr, adult.test$income)
f.perf <- performance(f.pred, "tpr", "fpr")
plot(f.perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(f.pred, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
library(randomForest)
forest.model <- randomForest(income ~ ., data = adult.train, importance=T)
forest.pred <- predict(forest.model, adult.test, type="class")
forestCM <- confusionMatrix(forest.pred, adult.test$income)
print(forestCM)
print.AESeSp(forestCM)
options("digits"=3)
sprintf("Accuracy of the model %f",forestCM$overall["Accuracy"])
sprintf("Total observations labelled as <=50K are %s",sum(forestCM$table[1,]))
sprintf("Total observations labelled as >50K are %s",sum(forestCM$table[2,]))
sprintf("Ans to (v) Given the response class distribution this makes sense. As there is a data imbalance , Random forest does increase sensitivity of the model at the cost of Specificity")
varImp <- varImpPlot(forest.model)
sprintf("Ans to (vi) MeanDecreaseAccuracy - Most Important 'capital_gain', least Important 'native_country' . MeanDecreaseGini - most important 'capital_gain', least important 'race'" )
print(forest.model)
sprintf("(vii) What is the number of variables tried at each split -> %s", 3 )
mtry <- tuneRF(adult.train[, names(adult.train) != "income"], adult.train[, names(adult.train) == "income"], ntreeTry=500,stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
print(mtry)
sprintf("Ans to (i) What is the default value of mtry - %s", floor(log(15, 2)))
sprintf("(ii) what is the optimal value of mtry? - Optimal when mtry = 2, { ...2.OOB    2    0.178}")
forest.mtry.model <- randomForest(income ~ ., data = adult.train, importance=T, mtry=2)
forest.mtry.pred <- predict(forest.mtry.model, adult.test, type="class")
forestMtryCM <- confusionMatrix(forest.mtry.pred, adult.test$income)
print.AESeSp(forestMtryCM)
varImp <- varImpPlot(forest.mtry.model)
sprintf("Ans to (5) MeanDecreaseAccuracy - Most Important 'capital_gain', least Important 'native_country' . MeanDecreaseGini - most important 'capital_gain', least important 'race'" )
print("There is a significant improvement in Balanced accuracy and Specificity, as now we are using optimal mTree split this was expected")
setwd("~/Desktop/Assignments&Coursework/422/Hw-2-March4/")
trans <- read.transactions("groceries.csv", sep=",")
summary(trans)
rules <- apriori(trans)
sprintf("Ans - (i) Got 0 rules for default support value of 0.1")
rules <- apriori(trans, parameter = list(support=0.001))
summary(rules)
sprintf("Ans - (ii)Got 410 rules for default support value of 0.001")
sprintf("Most frequently bought item and frequency")
sort(table(unlist(LIST(trans))), TRUE)[1:1]
sprintf("least frequently bought item and frequency")
sort(table(unlist(LIST(trans))))[1:2]
cat("\n\n## Top support ---- \n")
inspect(sort(rules, decreasing = T, by="support")[1:5])
cat("\n\n## Top confidence ----- \n")
inspect(sort(rules, decreasing = T, by="confidence")[1:5])
cat("\n\n## Minimum Support ----- \n")
inspect(sort(rules, decreasing = F, by="support")[1:5])
cat("\n\n## Minimum confidence ----- \n")
inspect(sort(rules, decreasing = F, by="confidence")[1:5])
adult.model
adult.model <- rpart(income ~ ., method="class", data=adult.train)
rpart.plot(adult.model, extra=104, type=4, main="Adult Income")
adult.model$variable.importance[1:3]
sprintf("The first split is done on predictor -> %s", rownames(adult.model$splits)[1])
sprintf("Predicted class of 1st Node -> %s", "<=50K")
sprintf("distribution of the <=50K and >50K at RootNode -> (0.7511 0.2489)")
adult.model <- rpart(income ~ ., method="class", data=adult.train)
rpart.plot(adult.model, extra=104, type=4, main="Adult Income")
adult.model$variable.importance[1:3]
sprintf("The first split is done on predictor -> %s", rownames(adult.model$splits)[1])
sprintf("Predicted class of 1st Node -> %s", "<=50K")
sprintf("distribution of the <=50K and >50K at RootNode -> 75.11% , 24.89%")
adult.model <- rpart(income ~ ., method="class", data=adult.train)
rpart.plot(adult.model, extra=104, type=4, main="Adult Income")
adult.model$variable.importance[1:3]
sprintf("The first split is done on predictor -> %s", rownames(adult.model$splits)[1])
sprintf("Predicted class of 1st Node -> %s", "<=50K")
sprintf("distribution of the <=50K and >50K at RootNode -> 75.11\% , 24.89\%")
adult.model <- rpart(income ~ ., method="class", data=adult.train)
rpart.plot(adult.model, extra=104, type=4, main="Adult Income")
adult.model$variable.importance[1:3]
sprintf("The first split is done on predictor -> %s", rownames(adult.model$splits)[1])
sprintf("Predicted class of 1st Node -> %s", "<=50K")
sprintf("distribution of the <=50K and >50K at RootNode -> .7511 , .2489")
adult.model
